require "consts.jinc"
require "util.jinc"
require "bucket.jinc"

inline
fn stash_path_blocks(
  reg u64 stash
) -> reg u64
{
  reg u64 p;
  p = (64u)[stash + 8 * PATH_BLOCKS_ADDR];
  return p;
}

inline
fn stash_overflow_blocks(
  reg u64 stash
) -> reg u64
{
  reg u64 p;
  p = (64u)[stash + 8 * OVERFLOW_BLOCKS_ADDR];
  return p;
}

// returns the index of the last nonempty blocks in overflow
fn _stash_overflow_ub(
  reg u64 stash,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  reg u64 i j overflow_blocks bid offset;
  reg u64 zero;
  reg bool b cond;

  #declassify i = (64u)[stash + 8 * OVERFLOW_CAPACITY_ADDR];  //! is it secret?
  i = #protect(i, msf);
  #declassify overflow_blocks = (64u)[stash + 8 * OVERFLOW_BLOCKS_ADDR];
  overflow_blocks = #protect(overflow_blocks, msf);
  offset = i;
  offset *= 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  overflow_blocks += offset;
  zero = #set0();
  while { cond = i > 0; } (cond) {
    msf = #update_msf(cond, msf);
    overflow_blocks -= 8 * DECRYPTED_BLOCK_SIZE_QWORDS; // (i - 1)
    #declassify bid = (64u)[overflow_blocks]; //! if bid is secret we cannot use it in condition
    bid = #protect(bid, msf);
    b = bid != EMPTY_BLOCK_ID;
    j = zero;
    j = #CMOVcc(b, i, j);
    i -= 1;
    b = bid != EMPTY_BLOCK_ID;
    i = #CMOVcc(b, zero, i);
  }
  msf = #update_msf(!cond, msf);
  return j, msf;
}

inline
fn stash_num_overflow_blocks(
  reg u64 stash
) -> reg u64
{
  reg u64 r i overflow_capacity overflow_blocks bid;
  reg u8 cond;
  reg bool b;
  r = 0; i = 0;
  overflow_blocks = stash_overflow_blocks(stash);
  overflow_capacity = (64u)[stash + 8 * OVERFLOW_CAPACITY_ADDR];
  while (i < overflow_capacity) {
    bid = (64u)[overflow_blocks + 8 * (i + BLOCK_DATA_SIZE_QWORDS)];
    b = bid != EMPTY_BLOCK_ID;
    cond = #SETcc(b);
    r += (64u)cond;
  }
  return r;
}

inline
fn _first_block_in_bucket_for_level(
  reg u64 stash,
  reg u64 level,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  reg u64 p offset;
  #declassify p = (64u)[stash + 8 * PATH_BLOCKS_ADDR];
  p = #protect(p, msf);
  offset = level * BLOCKS_PER_BUCKET;
  offset *= DECRYPTED_BLOCK_SIZE_QWORDS * 8;
  p = #LEA(p + offset);
  return p, msf;
}

inline
fn _cond_copy_block(
  reg u8 cond,
  reg u64 dst src
)
{
  inline int i;
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS {
    _cond_obv_cpy_u64(cond, dst, src);
    dst = #LEA(dst + 8);
    src = #LEA(src + 8);
  }
}

inline
fn _i_cond_copy_block(
  reg u8 cond,
  reg u64 dst,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] src
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS]
{
  reg u64 tmp va;
  inline int i;
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS {
    va = (64u)[dst];
    tmp = _ternary(cond, src[u64 i], va);
    (u64)[dst] = tmp;
    dst = #LEA(dst + 8);
  }
  return src;
}

inline
fn _cond_swap_blocks(
  reg u8 cond,
  reg u64 a b
)
{
  inline int i;
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS {
    _cond_obv_swap_u64(cond, a, b);
    a = #LEA(a + 8);
    b = #LEA(b + 8);
  }
}

inline
fn _i_cond_swap_blocks(
  reg u8 cond,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] a,
  reg u64 b
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS]
{
  reg u64 tmp rb;
  inline int i;
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS {
    rb = (64u)[b];
    tmp = _ternary(cond, a[u64 i], rb);
    (u64)[b] = tmp;
    a[u64 i] = _ternary(cond, rb, a[u64 i]);
    b = #LEA(b + 8);
  }
  return a;
}

// Precondition: `target` is an empty block OR no block in the bucket has ID equal to `target_block_id`
// Postcondition: No block in the bucket has ID equal to `target_block_id`, `target` is either empty or `target->id == target_block_id`.
fn stash_add_path_bucket(
  reg u64 stash bucket_store,
  reg u64 bucket_id target_block_id,
  reg u64 target,
  #msf reg u64 msf
) -> #msf reg u64
{
  reg u64 lvl bucket_blocks bid;
  reg u8 c;
  reg bool cond;
  inline int i;

  lvl = tree_path_level(bucket_id);
  bucket_blocks, msf = _first_block_in_bucket_for_level(stash, lvl, msf);
  msf = bucket_store_read_bucket_blocks(bucket_store, bucket_id, bucket_blocks, msf);
  for i = 0 to BLOCKS_PER_BUCKET
  {
    bid = (64u)[bucket_blocks];
    cond = bid == target_block_id;
    c = #SETcc(cond);
    _cond_swap_blocks(c, target, bucket_blocks);
    bucket_blocks += 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  }
  return msf;
}

fn _i_stash_add_path_bucket(
  reg u64 stash bucket_store,
  reg u64 bucket_id target_block_id,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] target,
  #msf reg u64 msf
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS], #msf reg u64
{
  reg u64 lvl bucket_blocks bid;
  reg u8 c;
  reg bool cond;
  inline int i;

  lvl = tree_path_level(bucket_id);
  bucket_blocks, msf = _first_block_in_bucket_for_level(stash, lvl, msf);
  msf = bucket_store_read_bucket_blocks(bucket_store, bucket_id, bucket_blocks, msf);
  for i = 0 to BLOCKS_PER_BUCKET
  {
    bid = (64u)[bucket_blocks];
    cond = bid == target_block_id;
    c = #SETcc(cond);
    target = _i_cond_swap_blocks(c, target, bucket_blocks);
    bucket_blocks += 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  }
  return target, msf;
}

// Precondition: `target` is an empty block OR no block in the overflow has ID equal to `target_block_id`
// Postcondition: No block in the overflow has ID equal to `target_block_id`, `target` is either empty or `target->id == target_block_id`.
fn stash_scan_overflow_for_target(
  reg u64 stash,
  reg u64 target_block_id,
  reg u64 target,
  #msf reg u64 msf
) -> #msf reg u64
{
  reg u64 ub i bid overflow_blocks;
  reg u8 c;
  reg bool cond;

  ub, msf = _stash_overflow_ub(stash, msf);
  overflow_blocks = (64u)[stash + 8 * OVERFLOW_BLOCKS_ADDR];
  i = 0;
  while (i < ub)
  {
    bid = (64u)[overflow_blocks];
    cond = bid == target_block_id;
    c = #SETcc(cond);
    _cond_swap_blocks(c, target, overflow_blocks);
    overflow_blocks += 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
    i += 1;
  }

  return msf;
}

fn _i_stash_scan_overflow_for_target(
  reg u64 stash,
  reg u64 target_block_id,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] target,
  #msf reg u64 msf
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS], #msf reg u64
{
  reg u64 ub i bid overflow_blocks;
  reg u8 c;
  reg bool b cond;

  ub, msf = _stash_overflow_ub(stash, msf);
  #declassify overflow_blocks = (64u)[stash + 8 * OVERFLOW_BLOCKS_ADDR];
  overflow_blocks = #protect(overflow_blocks, msf);
  i = 0;
  while { cond = i < ub; } (cond) {
    msf = #update_msf(cond, msf);
    bid = (64u)[overflow_blocks];
    b = bid == target_block_id;
    c = #SETcc(b);
    target = _i_cond_swap_blocks(c, target, overflow_blocks);
    overflow_blocks += 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
    i += 1;
  }
  msf = #update_msf(!cond, msf);
  return target, msf;
}

// Precondition: there is no block with ID `new_block->id` anywhere in the stash - neither the path_Stash nor the overflow.
inline
fn stash_add_block(
  reg u64 stash new_block
)
{
  reg u64 bid overflow_capacity overflow_blocks i;
  reg u8 c1 c2;
  reg bool b;

  overflow_blocks = stash_overflow_blocks(stash);
  overflow_capacity = [stash + 8 * OVERFLOW_CAPACITY_ADDR];

  c1 = 0; // inserted
  i = 0;
  while (i < overflow_capacity)
  {
    bid = [overflow_blocks];
    // cond
    c1 = !c1;
    b = bid == EMPTY_BLOCK_ID;
    c2 = #SETcc(b);
    c2 &= c1;
    _cond_copy_block(c2, overflow_blocks, new_block);
    c1 = !c1;
    c1 |= c2;
    i += 1;
    overflow_blocks = #LEA(overflow_blocks + 8 * DECRYPTED_BLOCK_SIZE_QWORDS);
  }
  // TODO: implement extend overflow and insert
}

inline
fn _i_stash_add_block(
  reg u64 stash,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] new_block,
  #msf reg u64 msf
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS], #msf reg u64
{
  reg u64 bid overflow_capacity overflow_blocks i;
  reg u8 c1 c2;
  reg bool b cond;

  #declassify overflow_blocks = stash_overflow_blocks(stash);
  overflow_blocks = #protect(overflow_blocks, msf);
  #declassify overflow_capacity = [stash + 8 * OVERFLOW_CAPACITY_ADDR];
  overflow_capacity = #protect(overflow_capacity, msf);

  c1 = 0; // inserted
  i = 0;
  while { cond = i < overflow_capacity; } (cond) {
    msf = #update_msf(cond, msf);
    bid = [overflow_blocks];
    // cond
    c1 = !c1;
    b = bid == EMPTY_BLOCK_ID;
    c2 = #SETcc(b);
    c2 &= c1;
    new_block = _i_cond_copy_block(c2, overflow_blocks, new_block);
    c1 = !c1;
    c1 |= c2;
    i += 1;
    overflow_blocks = #LEA(overflow_blocks + 8 * DECRYPTED_BLOCK_SIZE_QWORDS);
  }
  msf = #update_msf(!cond, msf);
  // TODO: implement extend overflow and insert
  return new_block, msf;
}

inline
fn _stash_assign_block_to_bucket_path(
  #spill_to_mmx reg u64 stash path,
  inline int index,
  #msf reg u64 msf
) -> #msf reg u64
{
  // spill_to_mmx variables
  #spill_to_mmx reg u64 bucket_assignments;
  // pointer variables
  reg u64 path_blocks bucket_occupancy;
  // temporary variables
  reg u64 r1 r2 bucket_id tree_bound tmp;
  // spill_to_mmx
  #spill_to_mmx reg u64 bid bpos;
  // boolean variables
  reg u8 c1 c2 c3;
  reg bool b cond;
  inline int max_level lvl offset;
  
  // the block cannot be assigned to this level or higher
  max_level = (index / BLOCKS_PER_BUCKET) + 1;

  #declassify path_blocks = (64u)[stash + 8 * PATH_BLOCKS_ADDR];
  path_blocks = #protect(path_blocks, msf);
  offset = index * 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  bid = (64u)[path_blocks + offset];
  bid = #protect(bid, msf);
  () = #spill(bid);
  bpos = (64u)[path_blocks + offset + 8];
  bpos = #protect(bpos, msf);
  () = #spill(bpos);

  #declassify bucket_occupancy = (64u)[stash + 8 * BUCKET_OCCUPANCY_ADDR];
  bucket_occupancy = #protect(bucket_occupancy, msf);
  #declassify bucket_assignments = (64u)[stash + 8 * BUCKET_ASSIGNMENTS_ADDR];
  bucket_assignments = #protect(bucket_assignments, msf);
  () = #spill(path, stash, bucket_assignments);

  c1 = #set0_8(); // is_assigned
  for lvl = 0 to max_level {
    r2 = (64u)[bucket_occupancy + 8 * lvl];
    r2 = #protect(r2, msf);
    () = #unspill(path);
    bucket_id = (64u)[path + 8 + 8 * lvl];
    bucket_id = #protect(bucket_id, msf);

    c1 = !c1;
    // is_valid
    tree_bound = tree_path_lower_bound(bucket_id);
    () = #unspill(bpos);
    b = tree_bound <= bpos;
    c2 = #SETcc(b);
    c2 &= c1;
    tree_bound = tree_path_upper_bound(bucket_id);
    () = #unspill(bpos);
    b = tree_bound >= bpos;
    c3 = #SETcc(b);
    c2 &= c3;
    // bucket_has_room
    b = r2 < BLOCKS_PER_BUCKET;
    c3 = #SETcc(b);
    c2 &= c3;
    // not is_empty
    () = #unspill(bid);
    b = bid != EMPTY_BLOCK_ID;
    c3 = #SETcc(b);
    c2 &= c3;
    // is_assigned = cond | is_assigned;
    c1 = !c1;
    c1 |= c2;
    b = c2 != 0;
    
    // If `b` is true, put it in the bucket: increment the bucket occupancy and set the bucket assignment
    // for this position.
    // increment this, it will only get saved if `b` is true.
    r1 = #LEA(r2 + 1);
    r1 = #CMOVcc(b, r1, r2);
    () = #unspill(bucket_assignments);
    (u64)[bucket_occupancy + 8 * lvl] = r1;
    r1 = (64u)[bucket_assignments + 8 * index];
    r1 = #protect(r1, msf);
    b = c2 != 0;
    tmp = (64u)lvl;
    r1 = #CMOVcc(b, tmp, r1);
    (u64)[bucket_assignments + 8 * index] = r1;
  }

  return msf;
}

inline
fn _stash_assign_block_to_bucket_overflow(
  #spill_to_mmx reg u64 stash path,
  reg u64 index,
  #msf reg u64 msf
) -> #msf reg u64
{
  // spill_to_mmx variables
  #spill_to_mmx reg u64 assignment_index bucket_assignments;
  // pointer variables
  reg u64 path_blocks bucket_occupancy;
  // temporary variables
  reg u64 r1 r2 bucket_id tree_bound tmp;
  // spill_to_mmx
  #spill_to_mmx reg u64 bid bpos;
  // boolean variables
  reg u8 c1 c2 c3;
  reg bool b cond;
  inline int lvl max_level;
  
  // the block cannot be assigned to this level or higher
  max_level = (64u)PATH_LENGTH;
  assignment_index = #LEA(BLOCKS_PER_BUCKET * PATH_LENGTH + index);

  #declassify path_blocks = (64u)[stash + 8 * PATH_BLOCKS_ADDR];
  path_blocks = #protect(path_blocks, msf);
  tmp = assignment_index;
  tmp *= 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  bid = (64u)[path_blocks + tmp];
  bid = #protect(bid, msf);
  () = #spill(bid);
  bpos = (64u)[path_blocks + tmp + 8];
  bpos = #protect(bpos, msf);
  () = #spill(bpos);

  #declassify bucket_occupancy = (64u)[stash + 8 * BUCKET_OCCUPANCY_ADDR];
  bucket_occupancy = #protect(bucket_occupancy, msf);
  #declassify bucket_assignments = (64u)[stash + 8 * BUCKET_ASSIGNMENTS_ADDR];
  bucket_assignments = #protect(bucket_assignments, msf);
  () = #spill(path, stash, assignment_index, bucket_assignments);

  c1 = #set0_8(); // is_assigned
  for lvl = 0 to max_level {
    r2 = (64u)[bucket_occupancy + 8 * lvl];
    r2 = #protect(r2, msf);
    () = #unspill(path);
    bucket_id = (64u)[path + 8 + 8 * lvl];
    bucket_id = #protect(bucket_id, msf);

    c1 = !c1;
    // is_valid
    tree_bound = tree_path_lower_bound(bucket_id);
    () = #unspill(bpos);
    b = tree_bound <= bpos;
    c2 = #SETcc(b);
    c2 &= c1;
    tree_bound = tree_path_upper_bound(bucket_id);
    () = #unspill(bpos);
    b = tree_bound >= bpos;
    c3 = #SETcc(b);
    c2 &= c3;
    // bucket_has_room
    b = r2 < BLOCKS_PER_BUCKET;
    c3 = #SETcc(b);
    c2 &= c3;
    // not is_empty
    () = #unspill(bid);
    b = bid != EMPTY_BLOCK_ID;
    c3 = #SETcc(b);
    c2 &= c3;
    // is_assigned = cond | is_assigned;
    c1 = !c1;
    c1 |= c2;
    b = c2 != 0;
    
    // If `b` is true, put it in the bucket: increment the bucket occupancy and set the bucket assignment
    // for this position.
    // increment this, it will only get saved if `b` is true.
    r1 = #LEA(r2 + 1);
    r1 = #CMOVcc(b, r1, r2);
    () = #unspill(assignment_index, bucket_assignments);
    (u64)[bucket_occupancy + 8 * lvl] = r1;
    r1 = (64u)[bucket_assignments + 8 * assignment_index];
    r1 = #protect(r1, msf);
    b = c2 != 0;
    tmp = lvl;
    r1 = #CMOVcc(b, tmp, r1);
    (u64)[bucket_assignments + 8 * assignment_index] = r1;
  }

  return msf;
}

inline
fn _stash_place_empty_blocks(
  reg u64 stash,
  #msf reg u64 msf
) -> #msf reg u64
{
  // standard variables
  reg u64 curr_bucket;
  // pointer variables
  reg u64 blocks bucket_occupancy bucket_assignments;
  // temporary variables
  reg u64 tmp_bo bid i tmp_r offset;
  // boolean variables
  reg u8 c1 c2;
  reg bool b cond;
  inline int j;

  #declassify blocks = (64u)[stash];
  blocks = #protect(blocks, msf);
  #declassify bucket_occupancy = (64u)[stash + 8 * BUCKET_OCCUPANCY_ADDR];
  bucket_occupancy = #protect(bucket_occupancy, msf);
  #declassify bucket_assignments = (64u)[stash + 8 * BUCKET_ASSIGNMENTS_ADDR];
  bucket_assignments = #protect(bucket_assignments, msf);
  curr_bucket = #set0();
  i = 0;
  while { cond = i < STASH_NUM_BLOCKS; } (cond) {
    msf = #update_msf(cond, msf);
    c1 = 0; // found_curr_bucket
    for j = 0 to PATH_LENGTH
    {
      c1 = !c1;
      // bucket_has_room
      #declassify tmp_bo = (64u)[bucket_occupancy + 8 * j];
      tmp_bo = #protect(tmp_bo, msf);
      b = tmp_bo != BLOCKS_PER_BUCKET;
      c2 = #SETcc(b);
      c2 &= c1;
      // set_curr_bucket
      b = c2 != 0;
      tmp_r = (64u)j;
      curr_bucket = #CMOVcc(b, tmp_r, curr_bucket);
      c1 = !c1;
      c1 |= c2;
    }
    tmp_bo = (64u)[bucket_occupancy + 8 * curr_bucket];
    offset = 8 * DECRYPTED_BLOCK_SIZE_QWORDS * i;
    bid = (64u)[blocks + offset];
    // cond_place_in_bucket
    b = bid == EMPTY_BLOCK_ID;
    c2 = #SETcc(b);
    b = tmp_bo < BLOCKS_PER_BUCKET;
    c1 = #SETcc(b);
    c1 &= c2;
    b = c1 != 0;

    tmp_r = #LEA(tmp_bo + 1);
    tmp_r = #CMOVcc(b, tmp_r, tmp_bo);
    (u64)[bucket_occupancy + 8 * curr_bucket] = tmp_r;
    tmp_bo = (64u)[bucket_assignments + 8 * i];
    tmp_r = #CMOVcc(b, curr_bucket, tmp_bo);
    (u64)[bucket_assignments + 8 * i] = tmp_r;
    i += 1;
  }
  msf = #update_msf(!cond, msf);
  // at the end, every bucket should be full
  return msf;
}

inline
fn _stash_assign_buckets(
  reg u64 stash path,
  #msf reg u64 msf
) -> #msf reg u64
{
  // standard variables
  reg u64 ub;
  // pointer variables
  reg u64 bucket_assignments bucket_occupancy;
  // temporary variables
  reg u64 it;
  reg bool cond;
  inline int i lvl;

  // assign all blocks to "overflow" - level UINT64_MAX and set all occupancy to 0
  #declassify bucket_assignments = (64u)[stash + 8 * BUCKET_ASSIGNMENTS_ADDR];
  bucket_assignments = #protect(bucket_assignments, msf);
  for i = 0 to STASH_NUM_BLOCKS { (u64)[bucket_assignments + 8 * i] = (64u)-1; }
  #declassify bucket_occupancy = (64u)[stash + 8 * BUCKET_OCCUPANCY_ADDR];
  bucket_occupancy = #protect(bucket_occupancy, msf);
  for i = 0 to PATH_LENGTH { (u64)[bucket_occupancy + 8 * i] = (64u)0; }

  // assign blocks in path to buckets first
  for lvl = 0 to PATH_LENGTH
  { for i = 0 to BLOCKS_PER_BUCKET
    {
      msf = _stash_assign_block_to_bucket_path(stash, path, lvl * BLOCKS_PER_BUCKET + i, msf);
    }
  }

  () = #spill(path);
  // assign blocks in overflow to buckets
  ub, msf = _stash_overflow_ub(stash, msf);
  () = #unspill(path);
  it = 0;
  while { cond = it < ub; } (cond) {
    msf = #update_msf(cond, msf);
    msf = _stash_assign_block_to_bucket_overflow(stash, path, it, msf);
    it = #LEA(it + 1);
  }
  msf = #update_msf(!cond, msf);

  // now assign empty blocks to fill the buckets
  msf = _stash_place_empty_blocks(stash, msf);

  return msf;
}

inline
fn _comp_blocks(
  reg u64 blocks block_level_assignments,
  reg u64 idx1 idx2
) -> reg u8
{
  reg u64 bla1 bla2 b1 b2 offset;
  reg u8 r s;
  reg bool b;

  bla1 = (64u)[block_level_assignments + 8 * idx1];
  bla2 = (64u)[block_level_assignments + 8 * idx2];
  offset = 8 * idx1;
  offset *= DECRYPTED_BLOCK_SIZE_QWORDS;
  offset += 8;
  b1 = (64u)[blocks + offset];
  offset = 8 * idx2;
  offset *= DECRYPTED_BLOCK_SIZE_QWORDS;
  offset += 8;
  b2 = (64u)[blocks + offset];

  b = b1 > b2;
  r = #SETcc(b);
  b = bla1 == bla2;
  s = #SETcc(b);
  r &= s;
  b = bla1 > bla2;
  s = #SETcc(b);
  r |= s;
  return r;
}

inline
fn _min(reg u64 a b) -> reg u64
{
  // b ^ ((a ^ b) & -((a - b) >> 63));
  reg u64 sub;
  sub = a;
  sub -= b;
  sub >>= 63;
  sub = -sub;
  a = a;
  a ^= b;
  a &= sub;
  b ^= a;
  return b;
}

inline
fn _odd_even_msort(
  #public reg u64 blocks block_level_assignments,
  reg u64 lb ub,
  #msf reg u64 msf
) -> #msf reg u64
{
  // indices variables
  reg u64 p k j i;
  // mmx
  #mmx reg u64 msf_s;
  // temporary variables
  reg u64 bound mini idx1 idx2 divisor one tmp addr1 addr2;
  // boolean variables
  reg u8 cond;
  reg bool b;

  () = #spill(blocks, block_level_assignments);
  ub = ub; lb = lb;
  ub -= lb;
  () = #spill(lb);
  p = 1; one = 1;
  while { b = p < ub; } (b) {
    msf = #update_msf(b, msf);
    k = p;
    () = #spill(p);
    while { b = k >= 1; } (b) {
      msf = #update_msf(b, msf);
      j = k;
      () = #unspill(p);
      p = #protect(p, msf);
      tmp = p;
      () = #spill(p);
      tmp -= 1;
      j &= tmp;
      j = j;
      k = k;
      bound = ub;
      bound -= k;
      while { b = j < bound; } (b) {
        msf = #update_msf(b, msf);
        () = #spill(bound);
        mini = ub;
        mini -= j;
        mini -= k;
        mini = _min(k, mini);
        i = 0;
        while { b = i < mini; } (b) {
          msf = #update_msf(b, msf);
          () = #spill(mini);
          idx1 = #LEA(i + j);
          idx2 = #LEA(idx1 + k);
          () = #unspill(p);
          p = #protect(p, msf);
          msf_s = #mov_msf(msf);
          divisor = p;
          () = #spill(p);
          divisor = #SHL(divisor, one);

          idx1 = idx1 / divisor;
          idx1 = idx1;
          idx2 = idx2;
          idx2 = idx2 / divisor;
          b = idx1 == idx2;
          msf = #mov_msf(msf_s);
          if (b) {
            msf = #update_msf(b, msf);
            msf_s = #mov_msf(msf);
            idx1 = #LEA(i + j);
            () = #spill(i, j, ub);
            () = #unspill(lb);
            lb = #protect(lb, msf);
            idx1 = #LEA(idx1 + lb);
            () = #spill(lb);
            idx2 = #LEA(idx1 + k);
            () = #spill(k);
            () = #unspill(blocks, block_level_assignments);
            blocks = #protect(blocks, msf);
            block_level_assignments = #protect(block_level_assignments, msf);
            cond = _comp_blocks(blocks, block_level_assignments, idx1, idx2);
            // swap
            addr1 = blocks;
            tmp = 8 * DECRYPTED_BLOCK_SIZE_QWORDS * idx1;
            addr1 += tmp;
            tmp = 8 * DECRYPTED_BLOCK_SIZE_QWORDS * idx2;
            addr2 = #LEA(blocks + tmp);
            () = #spill(blocks);
            _cond_swap_blocks(cond, addr1, addr2);

            addr1 = block_level_assignments;
            tmp = 8 * idx1;
            addr1 += tmp;
            tmp = 8 * idx2;
            addr2 = #LEA(block_level_assignments + tmp);
            () = #spill(block_level_assignments);
            _cond_obv_swap_u64(cond, addr1, addr2);
            msf = #mov_msf(msf_s);
            () = #unspill(i, j, k, ub);
            i = #protect(i, msf);
            j = #protect(j, msf);
            k = #protect(k, msf);
            ub = #protect(ub, msf);
          } else {
            msf = #update_msf(!b, msf);
          }
          () = #unspill(mini);
          mini = #protect(mini, msf);
          i = #LEA(i + 1);
        }
        msf = #update_msf(!b, msf);
        tmp = k;
        tmp = #SHL(tmp, one);
        j = #LEA(j + tmp);
        () = #unspill(bound);
        bound = #protect(bound, msf);
      }
      msf = #update_msf(!b, msf);
      k = #SHR(k, one);
    }
    msf = #update_msf(!b, msf);
    () = #unspill(p);
    p = #protect(p, msf);
    p = #SHL(p, one);
  }
  msf = #update_msf(!b, msf);

  return msf;
}

inline
fn stash_build_path(
  reg u64 stash path,
  #msf reg u64 msf
) -> #msf reg u64
{
  reg u64 overflow_size;
  reg u64 blocks bucket_assignments;

  msf = _stash_assign_buckets(stash, path, msf);

  #declassify blocks = [stash];
  blocks = #protect(blocks, msf);
  overflow_size, msf = _stash_overflow_ub(stash, msf);
  overflow_size = #LEA(overflow_size + PATH_LENGTH * BLOCKS_PER_BUCKET);

  #declassify bucket_assignments = [stash + 8 * BUCKET_ASSIGNMENTS_ADDR];
  bucket_assignments = #protect(bucket_assignments, msf);

  msf = _odd_even_msort(blocks, bucket_assignments, 0, overflow_size, msf);

  return msf;
}

inline
fn stash_clear(
  reg u64 stash,
  #msf reg u64 msf
) -> #msf reg u64
{
  reg u64 blocks;
  inline int i;

  #declassify blocks = [stash];
  blocks = #protect(blocks, msf);
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS * STASH_NUM_BLOCKS
  {
    (u64)[blocks + 8 * i] = -1;
  }

  return msf;
}