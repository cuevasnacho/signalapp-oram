require "params.jinc"
require "util.jinc"
require "pointers.jinc"

inline
fn __scan_position_map_set(
  #public reg u64 position_map,
  #secret reg u64 block_id position,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  reg u64 prev_position i;
  reg u8 cond;
  reg bool b wcond;

  prev_position = position;
  // linear scan of array so that every access looks the same.
  i = 0;
  while { wcond = i < POSITION_MAP_SIZE_1; } (wcond) {
    msf = #update_msf(wcond, msf);
    b = (64u)i == block_id;
    cond = #SETcc(b);
    
    reg u64 tmp va;
    va = (64u)[position_map];
    tmp = _ternary(cond, prev_position, va);
    (u64)[position_map] = tmp;
    prev_position = prev_position;
    prev_position = _ternary(cond, va, prev_position);
    prev_position = prev_position;

    position_map = #LEA(position_map + 8);
    i = #LEA(i + 1);
  }
  msf = #update_msf(!wcond, msf);
  return prev_position, msf;
}

inline
fn __position_map_read_then_set_linear(
  reg u64 position_map,
  reg u64 block_id,
  reg u64 position,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  reg u64 x data;
  #declassify data = [position_map + 8 * 3];  // *data
  data = #protect(data, msf);
  x, msf = __scan_position_map_set(data, block_id, position, msf);
  return x, msf;
}

// stash
inline
fn __stash_extend_overflow_1(
  reg u64 stash
)
{
  reg u64 old_num_blocks new_num_blocks;
  reg u64 addr old_len new_len flags new_addr prot fd offset err tmp;
  reg u64 blocks bucket_assignments;
  stack u64 blocks_s;
  inline int i;

  old_num_blocks = [stash + 8 * NUM_BLOCKS_ADDR];
  new_num_blocks = #LEA(old_num_blocks + STASH_GROWTH_INCREMENT);

  // (re)allocate new space, free the old
  blocks = [stash];
  old_len = old_num_blocks * DECRYPTED_BLOCK_SIZE;
  () = #spill(old_num_blocks);
  new_len = new_num_blocks * DECRYPTED_BLOCK_SIZE;
  flags = 1;
  new_addr = 0;
  blocks = blocks;
  new_addr = #mremap(blocks, old_len, new_len, flags, new_addr);
  [stash] = new_addr;
  blocks_s = new_addr;

  // free bucket_assignments
  bucket_assignments = [stash + 8 * BUCKET_ASSIGNMENTS_ADDR];
  () = #unspill(old_num_blocks);
  old_len = old_num_blocks * 8;
  err = #munmap(bucket_assignments, old_len);

  // mmap memory for bucket_assignments
  addr = 0;
  new_len = new_num_blocks * 8;
  prot = 0x1 | 0x2;   // PROT_READ | PROT_WRITE
  flags = 0x2 | 0x20; // MAP_PRIVATE | MAP_ANONYMOUS
  fd = -1;
  offset = 0;
  new_addr = #mmap(addr, new_len, prot, flags, fd, offset);
  [stash + 8 * BUCKET_ASSIGNMENTS_ADDR] = new_addr;

  // update our alias pointers
  blocks = blocks_s;
  tmp = #LEA(blocks + PATH_LENGTH_1 * BLOCKS_PER_BUCKET * DECRYPTED_BLOCK_SIZE);
  [stash + 8 * PATH_BLOCKS_ADDR] = blocks;
  [stash + 8 * OVERFLOW_BLOCKS_ADDR] = tmp;

  // initialize new memory
  () = #unspill(old_num_blocks);
  old_num_blocks *= DECRYPTED_BLOCK_SIZE;
  blocks = #LEA(blocks + old_num_blocks);
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS * STASH_GROWTH_INCREMENT
  {
    [blocks + 8 * i] = -1;
  }

  // update counts
  [stash + 8 * NUM_BLOCKS_ADDR] = new_num_blocks;
  [stash + 8 * OVERFLOW_CAPACITY_ADDR] += STASH_GROWTH_INCREMENT;
}

inline
fn __stash_place_empty_blocks_1(
  reg u64 stash,
  #msf reg u64 msf
) -> #msf reg u64
{
  // standard variables
  reg u64 curr_bucket num_blocks;
  // pointer variables
  reg u64 blocks bucket_occupancy bucket_assignments;
  // temporary variables
  reg u64 tmp_bo bid i tmp_r offset;
  // boolean variables
  reg u8 c1 c2;
  reg bool b cond;
  inline int j;

  blocks, msf = stash_blocks(stash, msf);
  bucket_occupancy, msf = stash_bucket_occupancy(stash, msf);
  bucket_assignments, msf = stash_bucket_assignments(stash, msf);
  num_blocks, msf = stash_num_blocks(stash, msf);
  curr_bucket = #set0();
  i = 0;
  while { cond = i < num_blocks; } (cond) {
    msf = #update_msf(cond, msf);
    c1 = 0; // found_curr_bucket
    for j = 0 to PATH_LENGTH_1
    {
      c1 = !c1;
      // bucket_has_room
      #declassify tmp_bo = (64u)[bucket_occupancy + 8 * j];
      tmp_bo = #protect(tmp_bo, msf);
      b = tmp_bo != BLOCKS_PER_BUCKET;
      c2 = #SETcc(b);
      c2 &= c1;
      // set_curr_bucket
      b = c2 != 0;
      tmp_r = (64u)j;
      curr_bucket = #CMOVcc(b, tmp_r, curr_bucket);
      c1 = !c1;
      c1 |= c2;
    }
    tmp_bo = (64u)[bucket_occupancy + 8 * curr_bucket];
    offset = 8 * DECRYPTED_BLOCK_SIZE_QWORDS * i;
    bid = (64u)[blocks + offset];
    // cond_place_in_bucket
    b = bid == EMPTY_BLOCK_ID;
    c2 = #SETcc(b);
    b = tmp_bo < BLOCKS_PER_BUCKET;
    c1 = #SETcc(b);
    c1 &= c2;
    b = c1 != 0;

    tmp_r = #LEA(tmp_bo + 1);
    tmp_r = #CMOVcc(b, tmp_r, tmp_bo);
    (u64)[bucket_occupancy + 8 * curr_bucket] = tmp_r;
    tmp_bo = (64u)[bucket_assignments + 8 * i];
    tmp_r = #CMOVcc(b, curr_bucket, tmp_bo);
    (u64)[bucket_assignments + 8 * i] = tmp_r;
    i += 1;
  }
  msf = #update_msf(!cond, msf);
  // at the end, every bucket should be full
  return msf;
}

// oram
inline
fn __i_oram_read_path_for_block_1(
  reg u64 oram path,
  reg u64 target_block_id,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] target,
  reg u64 new_position,
  #msf reg u64 msf
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS], #msf reg u64
{
  reg u64 stash bucket_store value;
  inline int i;

  () = #spill(new_position);
  stash, msf = oram_stash(oram, msf);
  bucket_store, msf = oram_bucket_store(oram, msf);
  for i = 0 to PATH_LENGTH_1
  {
    #declassify value = (64u)[path + 8 + 8 * i];
    value = #protect(value, msf);
    target, msf = _i_stash_add_path_bucket(stash, bucket_store, value, target_block_id, target, msf);
  }
  target, msf = _i_stash_scan_overflow_for_target(stash, target_block_id, target, msf);

  () = #unspill(new_position);
  target[u64 0] = target_block_id;
  target[u64 1] = new_position;
  return target, msf;
}

inline
fn __oram_put_1(
  reg u64 oram,
  reg u64 block_id start,
  reg u64 data,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  stack u64[DECRYPTED_BLOCK_SIZE_QWORDS] target_block_s;
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] target_block;
  // standard variables
  reg u64 new_position x prev_data;
  // pointer variables
  reg u64 stash path position_map bucket_store path_blocks;
  // temporary variables
  reg u64 bucket_id;
  inline int i max_position;

  () = #spill(start, data, block_id);
  target_block = target_block_s;
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS { target_block[i] = -1; }
  max_position = (64u)(1 << (PATH_LENGTH_1 - 1));

  new_position = _random_mod_by_pow_of_2(max_position);
  msf = #init_msf();

  new_position = new_position;
  position_map, msf = oram_position_map(oram, msf);
  () = #spill(oram, target_block);
  () = #unspill(block_id);
  x, msf = __position_map_read_then_set_linear(position_map, block_id, new_position, msf);
  x *= 2;

  () = #unspill(oram, target_block);
  oram = #protect(oram, msf);
  target_block = #protect_ptr(target_block, msf);
  path, msf = oram_path(oram, msf);
  tree_path_update(path, x, PATH_LENGTH_1);

  new_position *= 2;
  () = #spill(oram);
  () = #unspill(block_id);
  target_block, msf = __i_oram_read_path_for_block_1(oram, path, block_id, target_block, new_position, msf);
  () = #spill(path);
  () = #unspill(start, data);
  target_block[2:BLOCK_DATA_SIZE_QWORDS], prev_data =
    _i_write_accessor_partial_out(target_block[2:BLOCK_DATA_SIZE_QWORDS], start, data);
  () = #spill(prev_data);

  () = #unspill(oram);
  oram = #protect(oram, msf);
  stash, msf = oram_stash(oram, msf);
  () = #spill(oram);
  target_block, msf = _i_stash_add_block(stash, target_block, msf, PATH_LENGTH_1);

  () = #unspill(path);
  path = #protect(path, msf);
  msf = stash_build_path(stash, path, msf, PATH_LENGTH_1);
  () = #unspill(oram);
  oram = #protect(oram, msf);

  bucket_store, msf = oram_bucket_store(oram, msf);
  path_blocks, msf = stash_path_blocks(stash, msf);
  for i = 0 to PATH_LENGTH_1
  {
    #declassify bucket_id = [path + 8 + 8 * i];
    bucket_id = #protect(bucket_id, msf);
    msf = bucket_store_write_bucket_blocks(bucket_store, bucket_id, path_blocks, msf);
    path_blocks += BLOCKS_PER_BUCKET * DECRYPTED_BLOCK_SIZE_QWORDS * 8;
  }

  () = #unspill(prev_data);
  return prev_data, msf;
}

// position map
inline
fn _i_oram_position_map_set_1(
  reg u64 oram_position_map,
  reg u64 block_id position,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  reg u64 m_prime sh1 sh2 idx_in_block bid_for_index position_map prev_position;

  m_prime = [oram_position_map + 8 * EPB_CT_M_P_ADDR];
  sh1 = [oram_position_map + 8 * EPB_CT_SH1_ADDR];
  sh2 = [oram_position_map + 8 * EPB_CT_SH2_ADDR];

  idx_in_block = _ct_mod(block_id, BLOCK_DATA_SIZE_QWORDS, m_prime, sh1, sh2);

  bid_for_index = block_id_for_index_ct(oram_position_map, block_id);
  #declassify position_map = (64u)[oram_position_map + 8];

  prev_position, msf = __oram_put_1(position_map, bid_for_index, idx_in_block, position, msf);
  return prev_position, msf;
}

inline
fn __position_map_read_then_set_1(
  reg u64 position_map,
  reg u64 block_id,
  reg u64 position,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  reg u64 data prev_position;
  data = #LEA(position_map + 8 * 2);  // *data
  prev_position, msf = _i_oram_position_map_set_1(data, block_id, position, msf);
  return prev_position, msf;
}
